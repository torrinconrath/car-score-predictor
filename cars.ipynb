{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e21256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"chahiriiscoding/car-sales-data-from-cars-com\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random as rand\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import joblib\n",
    "import warnings\n",
    "from transformers import logging\n",
    "import joblib\n",
    "from math import log\n",
    "\n",
    "# Ignore specific warnings and logs\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.set_verbosity_error() \n",
    "\n",
    "# Read the file\n",
    "df = pd.read_csv(\"cars_data.csv\")\n",
    "\n",
    "# Make Car Model into two different columns\n",
    "if 'Car Model' in df.columns:\n",
    "    df[['Year', 'Model']] = df['Car Model'].str.extract(r'(\\d{4})\\s(.*)')\n",
    "    df = df.drop(columns=['Car Model'])\n",
    "\n",
    "if 'Price (USD)' in df.columns:\n",
    "    df = df.rename(columns={'Price (USD)': 'Price'})\n",
    "\n",
    "if 'Dealer Name' in df.columns:\n",
    "    df = df.rename(columns={'Dealer Name': 'Dealer'})\n",
    "\n",
    "# Standardize all matching rows to 'Certified'\n",
    "df['Condition'] = df['Condition'].apply(\n",
    "    lambda x: 'Certified' if 'certified' in str(x).lower() else x\n",
    ")\n",
    "# Clean condition column\n",
    "df['Condition'] = df['Condition'].replace([\n",
    "    'Prequalify now', 'stock_type', 'New & Used', np.nan\n",
    "], 'Other')\n",
    "\n",
    "# List of columns to clean\n",
    "columns_to_clean = ['Monthly Payment', 'Mileage', 'Price', 'Year']\n",
    "\n",
    "# Apply cleaning function to all specified columns\n",
    "df[columns_to_clean] = df[columns_to_clean].apply(lambda x: x.str.replace(r'\\D', '', regex=True))\n",
    "\n",
    "# Convert to numeric while preserving NaNs\n",
    "df[columns_to_clean] = df[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set empty Mileage values to 0\n",
    "df['Mileage'] = df['Mileage'].fillna(0)\n",
    "\n",
    "# Synthetic feature generation\n",
    "def random_accident(row):\n",
    "    return rand.choices([1, 0], weights=[30, 70], k=1)[0]  # 1 = accident, 0 = no accident\n",
    "\n",
    "def random_owners(row):\n",
    "    numbers = [0, 1, 2, 3, 4]\n",
    "    weights = [40, 40, 30, 20, 10]\n",
    "    return rand.choices(numbers, weights=weights, k=1)[0] \n",
    "\n",
    "def random_usage(row):\n",
    "    return rand.choices([1, 0], weights=[80, 20], k=1)[0]  # 1 = personal use, 0 = not personal\n",
    "\n",
    "# Apply the random features\n",
    "df['Accidents'] = df.apply(random_accident, axis=1)\n",
    "df['Owners'] = df.apply(random_owners, axis=1)\n",
    "df['Usage'] = df.apply(random_usage, axis=1) \n",
    "\n",
    "# Feature engineering\n",
    "current_year = datetime.now().year\n",
    "df['Age'] = current_year - df['Year']\n",
    "df['MilesPerYear'] = df['Mileage'] / (df['Age'] + 1)\n",
    "df['PricePerMile'] = df['Price'] / (df['Mileage'] + 1)\n",
    "\n",
    "# Hot-one encoding\n",
    "df = pd.get_dummies(df, columns=['Condition', 'Model', 'Dealer'], drop_first=False)\n",
    "\n",
    "# def simple_scoring(row):\n",
    "#     if pd.isna(row['Mileage']) or pd.isna(row['Price']) or pd.isna(row['Year']):\n",
    "#         return np.nan\n",
    "    \n",
    "#     age = current_year - row['Year']\n",
    "#     price_score = row['Price'] / 2000  \n",
    "#     mileage_score = row['Mileage'] / 2500    \n",
    "#     age_score = age * 5                     \n",
    "    \n",
    "#     weighted_sum = (0.5 * price_score) + (0.4 * mileage_score) + (0.1 * age_score)\n",
    "    \n",
    "#     if row['Accidents'] == 1:\n",
    "#         weighted_sum += 15  \n",
    "    \n",
    "#     if row['Owners'] == 2:\n",
    "#         weighted_sum += 5\n",
    "#     elif row['Owners'] > 2:\n",
    "#         weighted_sum += 10\n",
    "    \n",
    "#     if row['Usage'] == 0:  # Commercial usage penalty\n",
    "#         weighted_sum += 10\n",
    "    \n",
    "#     return weighted_sum\n",
    "\n",
    " \n",
    "# df['Score'] = df.apply(simple_scoring, axis=1)\n",
    "\n",
    "MEDIAN_PRICE = 25000  # median price baseline\n",
    "MAX_MILEAGE = 250000\n",
    "MAX_AGE = 30\n",
    "\n",
    "def enhanced_scoring(row):\n",
    "    # Check essential columns early\n",
    "    if pd.isna(row.get('Mileage')) or pd.isna(row.get('Year')):\n",
    "        return np.nan\n",
    "\n",
    "    age = current_year - row['Year']\n",
    "    if age < 0:\n",
    "        age = 0  # avoid negative age if year is in future\n",
    "\n",
    "    # Determine price_for_score\n",
    "    price = row.get('Price')\n",
    "    monthly_payment = row.get('Monthly Payment')\n",
    "\n",
    "    if not pd.isna(price):\n",
    "        price_for_score = price\n",
    "    elif not pd.isna(monthly_payment):\n",
    "        price_for_score = monthly_payment * 60  # estimate full price (5 years)\n",
    "    else:\n",
    "        return np.nan  # no price info at all\n",
    "\n",
    "    # Normalize and clamp values\n",
    "    clamped_mileage = min(row['Mileage'], MAX_MILEAGE)\n",
    "    clamped_age = min(age, MAX_AGE)\n",
    "\n",
    "    # Scores (log scale for price, power scale for others)\n",
    "    price_score = np.log1p(price_for_score / MEDIAN_PRICE) * 100\n",
    "    mileage_score = 100 * ((clamped_mileage / MAX_MILEAGE) ** 0.8)\n",
    "    age_score = 100 * ((clamped_age / MAX_AGE) ** 0.7)\n",
    "\n",
    "    weighted_sum = (0.60 * price_score) + (0.30 * mileage_score) + (0.10 * age_score)\n",
    "\n",
    "    # Condition adjustment\n",
    "    condition_new = row.get('Condition_New', 0) == 1\n",
    "    condition_certified = row.get('Condition_Certified', 0) == 1\n",
    "    condition_used = row.get('Condition_Used', 0) == 1\n",
    "\n",
    "    if condition_new:\n",
    "        weighted_sum -= 20\n",
    "    elif condition_certified:\n",
    "        weighted_sum -= 15\n",
    "    elif not condition_used:\n",
    "        weighted_sum += 5  # penalty for unknown condition\n",
    "\n",
    "    # Accidents adjustment\n",
    "    accidents = row.get('Accidents', 0)\n",
    "    if accidents == 1:\n",
    "        weighted_sum += 10\n",
    "    elif accidents > 1:\n",
    "        weighted_sum += 15  # harsher penalty for multiple accidents\n",
    "\n",
    "    # Owners adjustment (penalties scale moderately)\n",
    "    owners = row.get('Owners', 1)  # default 1 if missing\n",
    "    if owners == 2:\n",
    "        weighted_sum += 8\n",
    "    elif owners > 2:\n",
    "        weighted_sum += 8 + 3 * (owners - 2)  # scaled penalty\n",
    "\n",
    "    # Usage adjustment\n",
    "    usage = row.get('Usage', 1)  # assume 1 = non-commercial, 0 = commercial\n",
    "    if usage == 0:\n",
    "        # More penalty for commercial, scales with age\n",
    "        weighted_sum += 15 * (1 + clamped_age / MAX_AGE)\n",
    "\n",
    "    # Mileage per year adjustment\n",
    "    years_used = age if age > 0 else 1\n",
    "    miles_per_year = row['Mileage'] / years_used\n",
    "\n",
    "    if miles_per_year < 7500:\n",
    "        weighted_sum -= 5  # low mileage is good\n",
    "    elif miles_per_year > 15000:\n",
    "        weighted_sum += 10  # high mileage is bad\n",
    "\n",
    "    return weighted_sum\n",
    "\n",
    "# Apply to dataframe\n",
    "df['Score'] = df.apply(enhanced_scoring, axis=1)\n",
    "\n",
    "# Create training and testing data\n",
    "df = df.dropna(subset=['Monthly Payment', 'Mileage', 'Price', 'Year', 'Score'])\n",
    "\n",
    "X = df.drop(columns=['Score'])\n",
    "y = df['Score']\n",
    "\n",
    "# Feature selection (keep features with top 10% relevance = drop bottom 90%)\n",
    "selector = SelectPercentile(f_regression, percentile=50)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = [X.columns[i] for i in selector.get_support(indices=True)]\n",
    "print(f\"Selected {len(selected_features)} features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# Update feature list\n",
    "model_features = selected_features\n",
    "with open('model_features.json', 'w') as f:\n",
    "    json.dump(model_features, f)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y.values.reshape(-1, 1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Save X_train values\n",
    "X_train_df = pd.DataFrame(X_train, columns=model_features)\n",
    "X_train_df.to_pickle(\"X_train.pkl\")\n",
    "\n",
    "# XGBoost Benchmarking\n",
    "print(\"\\nXGBoost Benchmark:\")\n",
    "xgb = XGBRegressor(n_estimators=1000, learning_rate=0.01, early_stopping_rounds=50, random_state=42)\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost MSE: {xgb_mse:.2f}\")\n",
    "print(f\"XGBoost R²: {xgb_r2:.4f}\")\n",
    "print(f\"XGBoost MAE: {xgb_mae:.2f}\")\n",
    "\n",
    "# Scale target\n",
    "y_scaler = RobustScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "joblib.dump(y_scaler, 'model_scaler.pkl')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled.reshape(-1, 1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# Neural Network Implementation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"\\nUsing device:\", device)\n",
    "\n",
    "# Dataset Setup\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model Definition\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Training with Early Stopping\n",
    "model = ImprovedMLP(X_train.shape[1]).to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience = 100\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            val_loss += criterion(outputs, batch_y).item() * batch_X.size(0)\n",
    "    \n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best_car_model.pth')\n",
    "\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_car_model.pth'))\n",
    "y_scaler = joblib.load('model_scaler.pkl')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        all_preds.append(outputs.cpu())\n",
    "        all_targets.append(batch_y.cpu())\n",
    "\n",
    "predictions = torch.cat(all_preds).numpy()\n",
    "targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "preds_rescaled = y_scaler.inverse_transform(predictions)\n",
    "y_true_rescaled = y_scaler.inverse_transform(targets)\n",
    "\n",
    "print(\"All predictions (rescaled):\")\n",
    "print(preds_rescaled.flatten())\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_true_rescaled, preds_rescaled)\n",
    "r2 = r2_score(y_true_rescaled, preds_rescaled)\n",
    "mae = mean_absolute_error(y_true_rescaled, preds_rescaled)\n",
    "\n",
    "tolerance = 1\n",
    "within_tolerance = np.abs(y_true_rescaled - preds_rescaled) <= tolerance\n",
    "accuracy = np.mean(within_tolerance) * 100\n",
    "\n",
    "print(\"\\nFinal Evaluation:\")\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "print(f\"Test MAE: {mae:.2f}\")\n",
    "print(f\"Accuracy (within ±{tolerance}): {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM input processor\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "\n",
    "class CarScorePredictor:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.input_scaler = joblib.load('scaler.pkl')\n",
    "        self.output_scaler = joblib.load('model_scaler.pkl')\n",
    "\n",
    "        # Load model features\n",
    "        with open('model_features.json', 'r') as f:\n",
    "            self.model_features = json.load(f)\n",
    "\n",
    "        with open('all_make_model_keys.json', 'r') as f:\n",
    "            self.model_slugs = json.load(f)\n",
    "        \n",
    "        self.model_types = [slug.replace('_', ' ').replace('-', ' ').title() for slug in self.model_slugs]\n",
    "\n",
    "        # Get mean values for imputation from the training data\n",
    "        self.X_train_df = pd.read_pickle(\"X_train.pkl\")\n",
    "        self.default_values = self.X_train_df.mean()\n",
    "\n",
    "        # List of known categorical fields that were one-hot encoded\n",
    "        self.one_hot_prefixes = ['Condition_', 'Model_', 'Dealer_']  \n",
    "        \n",
    "        # Initialize the neural network\n",
    "        self.model = ImprovedMLP(input_size=len(self.model_features))  \n",
    "        self.model.load_state_dict(torch.load('best_car_model.pth', weights_only=True))\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Initialize LLM for information extraction\n",
    "        self.ner_pipeline = pipeline(\n",
    "            \"token-classification\",\n",
    "            model=\"dslim/bert-base-NER\",\n",
    "            aggregation_strategy=\"simple\"\n",
    "        )\n",
    "        \n",
    "        # Initialize LLM for text understanding\n",
    "        self.qa_pipeline = pipeline(\n",
    "            \"question-answering\",\n",
    "            model=\"distilbert-base-uncased-distilled-squad\"\n",
    "        )\n",
    "\n",
    "    def extract_car_info(self, text):\n",
    "        \"\"\"Extract structured car information from natural language\"\"\"\n",
    "        # Extract entities using NER\n",
    "        entities = self.ner_pipeline(text)\n",
    "\n",
    "        # Initialize default values\n",
    "        car_info = {\n",
    "            'Year': None,\n",
    "            'Model': None,\n",
    "            'Mileage': None,\n",
    "            'Price': None,\n",
    "            'Condition': None,\n",
    "            'Dealer': None,\n",
    "            'Monthly Payment': None,\n",
    "            'Accidents': 0,  # Default to no accidents\n",
    "            'Owners': 1,     # Default to 1 owner\n",
    "            'Usage': 1       # Default to personal use (1)\n",
    "        }\n",
    "\n",
    "\n",
    "        # Simple regex-based extractions for numerical fields\n",
    "        mileage_match = re.search(r'\\b([0-9,]+)\\s*(mi|miles)\\b\\.?', text, re.IGNORECASE)\n",
    "        price_match = re.search(r'\\$([0-9,]+)\\b(?![a-zA-Z/]| per)', text)\n",
    "        payment_match = re.search(r'\\$([0-9,]+)\\s*(?:/mo|per month)', text, re.IGNORECASE)\n",
    "        year_match = re.search(r'\\b(20\\d{2}|19\\d{2})\\b', text)\n",
    "\n",
    "        if mileage_match:\n",
    "            car_info['Mileage'] = int(mileage_match.group(1).replace(',', ''))\n",
    "        if price_match:\n",
    "            car_info['Price'] = int(price_match.group(1).replace(',', ''))\n",
    "        if payment_match:\n",
    "            car_info['Monthly Payment'] = int(payment_match.group(1).replace(',', ''))\n",
    "        if year_match:\n",
    "            car_info['Year'] = int(year_match.group(0))\n",
    "\n",
    "        # Extract accident information\n",
    "        if re.search(r'accidents?|accident history', text, re.IGNORECASE):\n",
    "            car_info['Accidents'] = 1\n",
    "\n",
    "        # Extract owner count\n",
    "        owners_match = re.search(r'(\\d+)\\s*(owners?|previous owners?)', text, re.IGNORECASE)\n",
    "        if owners_match:\n",
    "            car_info['Owners'] = int(owners_match.group(1))\n",
    "        elif re.search(r'one\\s*owner|single owner', text, re.IGNORECASE):\n",
    "            car_info['Owners'] = 1\n",
    "        elif re.search(r'two\\s*owners', text, re.IGNORECASE):\n",
    "            car_info['Owners'] = 2\n",
    "        elif re.search(r'three\\s*owners', text, re.IGNORECASE):\n",
    "            car_info['Owners'] = 3\n",
    "        elif re.search(r'four\\+?\\s*owners', text, re.IGNORECASE):\n",
    "            car_info['Owners'] = 4\n",
    "\n",
    "        # Extract usage type (mapped to your binary encoding)\n",
    "        if re.search(r'commercial|business|fleet', text, re.IGNORECASE):\n",
    "            car_info['Usage'] = 0  # Not personal use\n",
    "\n",
    "        # Pull entities from NER\n",
    "        for ent in entities:\n",
    "            label = ent['entity_group']\n",
    "            word = ent['word']\n",
    "\n",
    "            if label == 'ORG':\n",
    "                car_info['Dealer'] = word\n",
    "            elif label == 'MISC' or label == 'PRODUCT':\n",
    "                car_info['Model'] = word\n",
    "            elif label == 'DATE' and not car_info['Year']:\n",
    "                try:\n",
    "                    car_info['Year'] = int(re.search(r'\\d{4}', word).group(0))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # Try to find a matching model from the list\n",
    "        found_model = None\n",
    "        for model in self.model_types:\n",
    "            pattern = re.compile(rf'\\b{re.escape(model)}\\b', re.IGNORECASE)\n",
    "            if pattern.search(text):\n",
    "                found_model = model\n",
    "                break\n",
    "\n",
    "        if found_model:\n",
    "            car_info['Model'] = found_model\n",
    "\n",
    "        # Extract sales condition like New, Used, Certified, etc.\n",
    "        condition_match = re.search(r'\\b(New|Used|Certified(?: Pre-Owned)?)\\b', text, re.IGNORECASE)\n",
    "        if condition_match:\n",
    "            car_info['Condition'] = condition_match.group(1).title()\n",
    "\n",
    "        if not car_info['Dealer']:\n",
    "            dealer_match = re.search(\n",
    "                r'\\b(?:at dealer|dealer:|at)\\s+([A-Z][\\w&.,\\- ]{2,100})',\n",
    "                text,\n",
    "                re.IGNORECASE\n",
    "            )\n",
    "            if dealer_match:\n",
    "                # Clean extra whitespace and strip trailing punctuation\n",
    "                dealer_name = dealer_match.group(1).strip().rstrip('.,')\n",
    "                dealer_name = re.sub(r'\\bdealer\\b', '', dealer_name, flags=re.IGNORECASE).strip()\n",
    "                car_info['Dealer'] = dealer_name\n",
    "\n",
    "        return car_info\n",
    "    \n",
    "    def prepare_features(self, car_info):\n",
    "        \"\"\"Convert extracted car info into the model input vector\"\"\"\n",
    "        # Initialize feature row with zeros\n",
    "        feature_vector = np.zeros(len(self.model_features))\n",
    "        feature_df = pd.DataFrame([feature_vector], columns=self.model_features)\n",
    "\n",
    "        # Fill in numerical fields\n",
    "        for col in ['Year', 'Mileage', 'Price', 'Monthly Payment', 'Accidents', 'Owners']:\n",
    "            val = car_info.get(col)\n",
    "            if val is not None:\n",
    "                feature_df.at[0, col] = val\n",
    "            else:\n",
    "                feature_df.at[0, col] = self.default_values[col]\n",
    "\n",
    "        # Fill in one-hot fields\n",
    "        for prefix in self.one_hot_prefixes:\n",
    "            value = car_info.get(prefix)\n",
    "            if value is not None:\n",
    "                encoded = f\"{prefix}_{value}\"\n",
    "                if encoded in self.model_features:\n",
    "                    feature_df.at[0, encoded] = 1.0\n",
    "\n",
    "        # Apply input scaling\n",
    "        scaled_features = self.input_scaler.transform(feature_df.values)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        return torch.tensor(scaled_features, dtype=torch.float32).to(device)\n",
    "\n",
    "    \n",
    "    def predict_score(self, text_input):\n",
    "        \"\"\"Main prediction pipeline\"\"\"\n",
    "        # Extract information from text\n",
    "        car_info = self.extract_car_info(text_input)\n",
    "        print(\"Extracted car info:\", car_info)\n",
    "        \n",
    "        # Prepare features for model\n",
    "        features_tensor = self.prepare_features(car_info)\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model(features_tensor)\n",
    "            score = self.output_scaler.inverse_transform(prediction.cpu().numpy().reshape(-1, 1))\n",
    "        \n",
    "        return score[0][0]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CarScorePredictor()\n",
    "\n",
    "    # Define options for different fields\n",
    "    years = [str(y) for y in range(1998, 2023)]\n",
    "\n",
    "    # Extract model names from the one-hot encoded features (removing \"Model_\" prefix)\n",
    "    sample_models = [feature.replace(\"Model_\", \"\") for feature in model_features if feature.startswith(\"Model_\")]\n",
    "    mileages = [f\"{x:,}\" for x in range(0, 250001, 5000)]\n",
    "    prices = [f\"${x:,}\" for x in range(4000, 120001, 2000)]\n",
    "    conditions = [feature.replace(\"Condition_\", \"\") for feature in model_features if feature.startswith(\"Condition_\")]\n",
    "    dealers = [feature.replace(\"Dealer_\", \"\") for feature in model_features if feature.startswith(\"Dealer_\")]\n",
    "    payments = [f\"${x:,}\" for x in range(120, 3001, 50)]\n",
    "    \n",
    "    # Options for additional features\n",
    "    accident_options = [\"no accidents\", \"accident reported\", \"clean history\", \"1 accident\", \"accident history\"]\n",
    "    owner_options = [\"1 owner\", \"2 owners\", \"3 owners\", \"4+ owners\", \"single owner\", \"one previous owner\"]\n",
    "    usage_options = [\"private use\", \"commercial use\", \"fleet use\", \"personal use\", \"business use\"]\n",
    "\n",
    "    # Create templates with varying levels of information\n",
    "    basic_templates = [\n",
    "        \"{year} {model}, {mileage} miles, {price}, {condition} condition\",\n",
    "        \"{model} from {year} with {mileage} miles, {price}\",\n",
    "        \"Dealer: {dealer}. {year} {model}, {mileage} miles, {price}\",\n",
    "        \"Looking at a {year} {model}, {condition} condition, {price}\"\n",
    "    ]\n",
    "    \n",
    "    intermediate_templates = [\n",
    "        \"{year} {model}, {mileage} miles, {price}, {condition} condition, {owner}\",\n",
    "        \"{model} ({year}), {mileage} miles, {price}, {usage}, {accident}\",\n",
    "        \"Found a {year} {model}, {condition} condition, {price}, {owner}, {accident}\",\n",
    "        \"{year} {model}, {mileage} miles, {price}, {usage}, dealer: {dealer}\"\n",
    "    ]\n",
    "    \n",
    "    full_info_templates = [\n",
    "        \"{year} {model}, {mileage} miles, {price}, {condition} condition, {owner}, {accident}, {usage}\",\n",
    "        \"Dealer: {dealer}. {year} {model}, {mileage} miles, {price}, {condition}, {owner}, {usage}, {accident}\",\n",
    "        \"Complete info: {year} {model}, {mileage} miles, {price}, {condition}, {owner}, {accident}, {usage}, dealer: {dealer}\"\n",
    "    ]\n",
    "\n",
    "    # Combine all templates\n",
    "    all_templates = basic_templates + intermediate_templates + full_info_templates\n",
    "\n",
    "    # Generate 100 diverse test queries with varying information completeness\n",
    "    test_queries = []\n",
    "    for _ in range(100):\n",
    "        template = random.choice(all_templates)\n",
    "        \n",
    "        # For basic templates, don't include all optional features\n",
    "        if template in basic_templates:\n",
    "            query = template.format(\n",
    "                year=random.choice(years),\n",
    "                model=random.choice(sample_models),\n",
    "                mileage=random.choice(mileages),\n",
    "                price=random.choice(prices),\n",
    "                condition=random.choice(conditions),\n",
    "                dealer=random.choice(dealers)\n",
    "            )\n",
    "        else:\n",
    "            query = template.format(\n",
    "                year=random.choice(years),\n",
    "                model=random.choice(sample_models),\n",
    "                mileage=random.choice(mileages),\n",
    "                price=random.choice(prices),\n",
    "                condition=random.choice(conditions),\n",
    "                dealer=random.choice(dealers),\n",
    "                accident=random.choice(accident_options),\n",
    "                owner=random.choice(owner_options),\n",
    "                usage=random.choice(usage_options)\n",
    "            )\n",
    "        test_queries.append(query)\n",
    "\n",
    "    # Add some manual examples that cover edge cases\n",
    "    test_queries.extend([\n",
    "        \"2021 Toyota Camry with 35,000 miles for $25,000 in used condition from AutoNation, no accidents, 1 owner\",\n",
    "        \"2019 Honda Accord, 75,000 miles, $18,500, used condition, personal use\",\n",
    "        \"Tesla Model 3 2022 with 12,000 miles priced at $42,000, clean history\",\n",
    "        \"Ford F-150 2017, 120,000 miles, $22,999, used condition, commercial use, accident reported\",\n",
    "        \"2018 Nissan Rogue, $16,500, 85,000 miles, used condition, 3 owners\",\n",
    "        \"2018 Subaru Baja, $500 per month, 2,000 miles, used condition, 1 owner\",\n",
    "        \"2022 Toyota Camry with 12,000 miles for $9,000 in used condition, personal use, 1 owner, clean history\"\n",
    "    ])\n",
    "    \n",
    "    min_score = 1000 # Will store smallest tuple query\n",
    "    min_query = \"\"\n",
    "\n",
    "    # Test the predictor with sample queries\n",
    "    for i, query in enumerate(test_queries):  # Just test first 10 for demonstration\n",
    "        try:\n",
    "            score = predictor.predict_score(query)\n",
    "\n",
    "            if (score < min_score) and (query != \"\"):\n",
    "                min_score = score\n",
    "                min_query = query\n",
    "            \n",
    "            print(f\"Query {i+1}: {query}\")\n",
    "            print(f\"Predicted Score: {score:.2f}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {query}\")\n",
    "            print(f\"Error: {str(e)}\\n\")\n",
    "    \n",
    "    print(f\"Min Query: {min_query}\")\n",
    "    print(f\"Min Score: {min_score:.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
